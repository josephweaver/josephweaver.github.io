# MTH 868 — Lecture 07
**Date:** 2026-01-28  
**Topic:** Regular points, critical points, submanifolds, and regular level sets

---

## 1. Setup and Recall

Let  
- \( F : M \to N \) be a smooth map between smooth manifolds.

### Critical vs Regular Points and Values

- A **critical point** \( p \in M \) is one where the differential
  \[
  dF_p : T_p M \to T_{F(p)} N
  \]
  is **not surjective**.

- A **regular point** is a point where \( dF_p \) *is* surjective.

- A **critical value** is a point in \( N \) that is the image of *some* critical point.
- A **regular value** is a point in \( N \) that is *not* a critical value.

> **Stats intuition:**  
> This is rank deficiency. A critical point is where your Jacobian drops rank.  
> Regular values are outputs where the Jacobian behaves nicely everywhere in the preimage.

---

## 2. Characterizing Critical Points for \( F : M \to \mathbb{R} \)

### Proposition

Let \( F : M \to \mathbb{R} \) be smooth.  
Then \( p \in M \) is a **critical point** iff:

### Equivalent conditions

1. In **any chart** \( (U, \varphi = (x^1, \dots, x^n)) \) around \( p \),
   \[
   \frac{\partial F}{\partial x^i}(p) = 0 \quad \forall i
   \]

2. There **exists** a chart where all partial derivatives vanish.

---

### Why this works (lecture explanation)

- The differential \( dF_p \) is a linear map
  \[
  dF_p : T_p M \to T_{F(p)} \mathbb{R}
  \]

- Since \( \mathbb{R} \) is 1-dimensional, surjectivity means:
  - the linear map is **non-zero**

- In coordinates, using the basis
  \[
  \left\{ \frac{\partial}{\partial x^i} \bigg|_p \right\}
  \]
  the differential is represented by the **row vector**
  \[
  [ \partial_1 F(p) \;\; \cdots \;\; \partial_n F(p) ]
  \]

- This has rank 0 **iff all entries are zero**

> **Key invariant:**  
> “All partial derivatives vanish” is a **coordinate-independent** statement, even though it *looks* coordinate-dependent.

---

## 3. Why Partial Derivatives Vanishing Is Chart-Independent

Suppose \( (U, x^i) \) and \( (V, y^j) \) are two charts near \( p \).

By the chain rule:
\[
\frac{\partial F}{\partial y^j}
=
\sum_i
\frac{\partial x^i}{\partial y^j}
\frac{\partial F}{\partial x^i}
\]

In matrix form:
\[
[\partial_{y} F]
=
[\partial_x F] \cdot J(\varphi \circ \psi^{-1})
\]

- The Jacobian of the transition map is **invertible**
- Therefore:
  \[
  [\partial_x F] = 0
  \iff
  [\partial_y F] = 0
  \]

> **Stats analogy:**  
> Gradient = 0 is invariant under reparameterization  
> Just like score functions transform covariantly.

---

## 4. Regular Submanifolds (Definition)

Let \( S \subset N \).

### Definition

\( S \) is a **regular \( k \)-dimensional submanifold** of \( N \) if:

For every \( p \in S \), there exists a chart  
\( (U, \varphi = (x^1, \dots, x^n)) \) of \( N \) about \( p \) such that:
\[
S \cap U
=
\{ q \in U \mid x^{k+1}(q) = \cdots = x^n(q) = 0 \}
\]

> These charts are called **adapted charts**

---

### Geometric meaning

- Locally, \( S \) *looks like* \( \mathbb{R}^k \)
- The remaining \( n-k \) coordinates are “normal directions”

> **Important:**  
> Not every chart does this.  
> The definition is about **existence**, not universality.

---

### Examples

1. **Linear subspaces**
   - \( xy \)-plane in \( \mathbb{R}^3 \)

2. **Graphs of smooth functions**

Let \( f \in C^\infty(\mathbb{R}) \).  
Define:
\[
S = \{ (x, f(x)) \} \subset \mathbb{R}^2
\]

Define the chart:
\[
\varphi(x,y) = (x, y - f(x))
\]

Then:
- \( S \) corresponds to \( \{ y = 0 \} \)
- Inverse chart:
  \[
  \varphi^{-1}(u,v) = (u, v + f(u))
  \]

Thus graphs are smooth 1-manifolds.

---

## 5. Codimension

### Definition

\[
\operatorname{codim}(S) = \dim(N) - \dim(S)
\]

- Often easier to reason about constraints than dimensions
- Each independent equation increases codimension by 1

---

## 6. Level Sets

### Definition

Let \( F : N \to M \) be smooth, \( c \in M \).

The **\( c \)-level set** is:
\[
F^{-1}(c) = \{ x \in N \mid F(x) = c \}
\]

---

### Example: Sphere

Let:
\[
F(x,y,z) = x^2 + y^2 + z^2
\]

Then:
\[
F^{-1}(1) = S^2 \subset \mathbb{R}^3
\]

Compute differential:
\[
dF_{(x,y,z)} = [2x \;\; 2y \;\; 2z]
\]

- Surjective everywhere except at \( (0,0,0) \)
- Since \( (0,0,0) \notin F^{-1}(1) \), **1 is a regular value**

---

## 7. Implicit Function Theorem View

Let:
\[
G = F - 1
\quad \Rightarrow \quad
F^{-1}(1) = G^{-1}(0)
\]

At the north pole \( (0,0,1) \):
\[
\frac{\partial G}{\partial z} = 2 \neq 0
\]

By the **Implicit Function Theorem**:
- There exists a neighborhood where
  \[
  z = h(x,y)
  \]
- The level set is locally the **graph of a smooth function**

> **Conclusion:**  
> Regular level sets are smooth submanifolds.

---

## 8. Regular Level Set Theorem (Main Result)

### Theorem

Let \( F : N \to M \) be smooth.

If \( c \in M \) is a **regular value**, then:
- \( F^{-1}(c) \) is a smooth submanifold
- Dimension:
  \[
  \dim F^{-1}(c) = \dim N - \dim M
  \]
- Codimension:
  \[
  \operatorname{codim}(F^{-1}(c)) = \dim M
  \]

---

### Proof sketch (what actually happened in lecture)

1. Reduce to \( c = 0 \) via \( G = F - c \)
2. Use surjectivity of \( dF_p \) to find a nonzero partial derivative
3. Reorder coordinates if needed
4. Apply inverse / implicit function theorem
5. Show local model is coordinate hyperplane

> **Stats translation:**  
> Regular value = full-rank Jacobian everywhere on the constraint set  
> ⇒ constraint surface is smooth, dimension reduced by number of constraints

---

## 9. Why This Matters (Big Picture)

- This theorem underlies:
  - constraint optimization
  - Lagrange multipliers
  - manifolds defined by equations
  - likelihood surfaces under constraints
  - parameter identifiability

If you remember **one thing**:

> **Regular = full rank Jacobian ⇒ smooth geometry**

Everything else is machinery to make that precise.

---
