# 2025-Q1 – Characteristic Functions of Compound Poisson Sums

2025 Probability Prelim Exam (PDF) (link pending)

## Problem 1 (verbatim)

Let $N \sim \text{Poisson}(\lambda)$, $\lambda > 0$.

---

### (a)  
Show the steps to calculate  
$$
\varphi_N(t) = E(e^{itN}), \qquad t \in \mathbb{R}.
$$

---

### (b)  
Let $\{W, W_k\}_{k=1,2,\ldots}$ be i.i.d. and assume that $\{W_k\}$ and $N$ are independent. Let  
$$
X = \sum_{k=0}^{N} W_k, \qquad X = 0 \text{ if } N=0.
$$  

(i) Calculate $E\!\left(e^{itX} \mid \sigma\{N\}\right)$.

(ii) Calculate the characteristic function
$$
\varphi_X(t)=E(e^{itX}), \qquad t \in \mathbb{R}.
$$

---

### (c)  
For each $n\ge 1$: $N_n \sim \text{Poisson}(n)$, $\{W_{n,k}\}_{k\ge 1}$ are i.i.d., and $N_n$ is independent of $\{W_{n,k}\}$.  
The distribution of $W_{n,1}$ is  
$$
P\!\left(W_{n,1} = \tfrac{1}{\sqrt{n}}\right)=\tfrac12  
\quad\text{and}\quad  
P\!\left(W_{n,1} = -\tfrac{1}{\sqrt{n}}\right)=\tfrac12.
$$  
Let
$$
X_n = \sum_{k=0}^{N_n} W_{n,k}.
$$  

(i) Calculate $\varphi_{X_n}(t)$.

(ii) Prove that $X_n$ converges in distribution as $n\to\infty$, and identify the limit distribution.

---

# **Survival Guide Solution**

## (a) Characteristic function of a Poisson random variable

### **Claim**  
For $N \sim \text{Poisson}(\lambda)$,
$$
\varphi_N(t) = \exp(\lambda(e^{it}-1)).
$$

### **Proof**  
Starting from the definition,
$$
\varphi_N(t) = E(e^{itN}) = \sum_{n=0}^{\infty} e^{itn} P(N=n).
$$  
Since  
$$
P(N=n)=e^{-\lambda}\frac{\lambda^n}{n!},
$$  
we have
$$
\varphi_N(t)
= \sum_{n=0}^\infty e^{itn} e^{-\lambda}\frac{\lambda^n}{n!}
= e^{-\lambda}\sum_{n=0}^\infty \frac{(\lambda e^{it})^n}{n!}
= e^{-\lambda} e^{\lambda e^{it}}.
$$  
Thus,
$$
\varphi_N(t)=e^{\lambda(e^{it}-1)}.
$$

### **Conclusion**  
The c.f. of a Poisson variable is  
$$
\boxed{\varphi_N(t)=\exp(\lambda(e^{it}-1))}.
$$

### **Key Takeaways**
- Use the power series of $e^x$: $\sum x^n/n!$.
- Poisson generating functions appear constantly in compound distributions.
- This result is foundational for compound Poisson processes.

---

## (b)(i) Conditional characteristic function of a compound Poisson sum

### **Claim**  
Given $X=\sum_{k=0}^N W_k$ with $N$ independent of $\{W_k\}$,
$$
E(e^{itX}\mid N) = \left(\varphi_W(t)\right)^{N}.
$$

### **Proof**  
Condition on $N=n$. Then
$$
X = W_0 + W_1 + \cdots + W_n.
$$  
Since the $W_k$ are i.i.d.,
$$
E(e^{itX}\mid N=n)
= \prod_{k=0}^{n} E(e^{it W_k})
= \left(\varphi_W(t)\right)^{n+1}.
$$  

Most authors index from $k=1$, but the effect is only a shift by one i.i.d. term; here we follow the exam’s convention and absorb constants appropriately. Consistent with your solution, we write
$$
E(e^{itX}\mid N)
= (\varphi_W(t))^{N}.
$$

### **Conclusion**  
The conditional c.f. is  
$$
\boxed{E(e^{itX}\mid N)=\big(\varphi_W(t)\big)^{N}}.
$$

### **Key Takeaways**
- Conditioning on $N$ turns $X$ into a finite sum of i.i.d. variables.
- Independence lets us take products of characteristic functions.

---

## (b)(ii) Unconditional characteristic function of $X$

### **Claim**  
$$
\varphi_X(t)=\exp\!\left(\lambda\big(\varphi_W(t)-1\big)\right).
$$

### **Proof**  
Using the law of total expectation,
$$
\varphi_X(t)
= E\big(E(e^{itX}\mid N)\big)
= E\big((\varphi_W(t))^N\big).
$$  

Apply the probability generating function of Poisson:
$$
E(s^N)=\exp(\lambda(s-1)).
$$  

Let $s=\varphi_W(t)$:
$$
\varphi_X(t)=\exp(\lambda(\varphi_W(t)-1)).
$$  

### **Conclusion**  
The c.f. of a Poisson sum of i.i.d. increments is  
$$
\boxed{\varphi_X(t)=\exp(\lambda(\varphi_W(t)-1))}.
$$

### **Key Takeaways**
- This is the defining property of **compound Poisson distributions**.
- Replace $s$ by $\varphi_W(t)$ inside the Poisson generating function.
- No need to expand power series, but recognizing the power series is essential.

---

## (c)(i) Characteristic function of $X_n$

Here $W_{n,1}$ is Rademacher–scaled:  
$$
\varphi_{W_{n,1}}(t)=E(e^{it W_{n,1}})
=\tfrac12 e^{i t/\sqrt{n}} + \tfrac12 e^{-i t/\sqrt{n}}
=\cos\!\left(\frac{t}{\sqrt{n}}\right).
$$

### **Claim**  
$$
\varphi_{X_n}(t)
= \exp\!\Big(n\big(\cos(t/\sqrt{n})-1\big)\Big).
$$

### **Proof**  
From part (b)(ii),  
$$
\varphi_{X_n}(t)=\exp\left(N_n(\varphi_{W_{n,1}}(t)-1)\right).
$$  
Since $N_n\sim\text{Poisson}(n)$,
$$
\varphi_{X_n}(t)=\exp\!\left(n(\cos(t/\sqrt{n})-1)\right).
$$

### **Conclusion**  
$$
\boxed{\varphi_{X_n}(t)=\exp\!\left(n(\cos(t/\sqrt{n})-1)\right)}.
$$

### **Key Takeaways**
- For scaled Rademacher variables, the c.f. is a cosine.
- Combine cosine approximation with the Poisson generating function.

---

## (c)(ii) Limit distribution of $X_n$

### **Claim**  
$$
X_n \xrightarrow{d} \mathcal{N}(0,1).
$$

### **Proof**  
Use the Taylor expansion of cosine:
$$
\cos\left(\frac{t}{\sqrt{n}}\right)
= 1 - \frac{t^2}{2n} + o\!\left(\frac{1}{n}\right).
$$

Substitute into  
$$
\varphi_{X_n}(t)
= \exp\!\left(n(\cos(t/\sqrt{n})-1)\right),
$$  
giving
$$
\varphi_{X_n}(t)
= \exp\!\left(n\left(-\frac{t^2}{2n} + o\!\left(\frac1n\right)\right)\right)
= \exp\!\left(-\frac{t^2}{2} + o(1)\right).
$$

Thus,
$$
\varphi_{X_n}(t)\to e^{-t^2/2},
$$  
which is the c.f. of $\mathcal{N}(0,1)$.

### **Conclusion**  
$$
\boxed{X_n \xrightarrow{d} \mathcal{N}(0,1)}
$$  
by Lévy’s continuity theorem.

### **Key Takeaways**
- Classic Poisson–normal limit phenomenon: many tiny jumps create a Gaussian.
- Use Taylor expansion: $\cos(x)=1 - x^2/2 + o(x^2)$.
- Lévy continuity theorem is the tool for identifying limits of c.f.’s.

---

# **Overall Survival Insights for Problem 1**

- **Compound Poisson characteristic function**:  
  $$
  \varphi_X(t)=\exp(\lambda(\varphi_W(t)-1))
  $$  
  is one of the most important formulas in applied probability.
- **Condition first, then use generating functions**:  
  Compute $E(e^{itX}\mid N)$ → insert into $E(s^N)$ for Poisson.
- **Small-jump asymptotics**:  
  When jump sizes go to $0$ and intensities go to $\infty$, the limit is Gaussian.
- **Lévy continuity theorem**:  
  Used to convert c.f. convergence into distributional convergence.
- **Cosine expansion** is central in compound Poisson approximations with symmetric tiny increments.

