---
title: "2018 Problem 3 — Bernoulli Binary Expansion and Uniform Limit"
layout: default
math: true
---

# **Probability Prelim — August 2018**  
**Problem 3**  
:contentReference[oaicite:1]{index=1}

>noulli}(1/2)$.  Let $X, X_1, X_2, \dots$ be iid sequence of random variables where $X \sim \text{Ber 
> Let
> $$
> S_n = \sum_{k=1}^n \frac{X_k}{2^k}, \qquad n \ge 1.
> $$
>
> **(a)** Prove the following.
>
> **(i)** $S_n$ converges a.s. as $n \to \infty$. Denote the limit random variable by $S_\infty$.
>
> **(ii)** $E[S_n] \xrightarrow[n\to\infty]{} E[S_\infty]$ and
> $\operatorname{Var}(S_n) \xrightarrow[n\to\infty]{} \operatorname{Var}(S_\infty)$.  
> Calculate $E[S_\infty]$ and $\operatorname{Var}(S_\infty)$.
>
> ---
>
> **(b)** Prove that
> $$
> \prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}
> $$
> converges as $n\to\infty$ for each $t\in\mathbb{R}$.
>
> ---
>
> **(c)** It is known that
> $$
> \prod_{k=1}^\infty \frac{1 + e^{i t/2^k}}{2}
> = \frac{e^{it} - 1}{it}, \qquad t\in\mathbb{R}.
> $$
> Use this identity to find the distribution of $S_\infty$.

---

# **(a)(i) Almost Sure Convergence of $S_n$**

## **Assumptions / Notation**

- $X_k \sim \text{Bernoulli}(1/2)$ iid, so $0 \le X_k \le 1$ almost surely.
- $S_n = \sum_{k=1}^n X_k / 2^k$.

---

## **Solution**

### **Claim.**  
$$
S_n \xrightarrow[\;n\to\infty\;]{a.s.} S_\infty
$$
for some finite random variable $S_\infty$.

### **Proof.**

**Step 1. Show monotonicity.**  
For each $\omega$,
\[
S_{n+1}(\omega) - S_n(\omega) = \frac{X_{n+1}(\omega)}{2^{n+1}} \ge 0.
\]
So $(S_n(\omega))_{n\ge1}$ is a **nondecreasing** sequence for every $\omega$.

**Step 2. Show boundedness.**  
Since $0 \le X_k(\omega) \le 1$,
\[
S_n(\omega)
= \sum_{k=1}^n \frac{X_k(\omega)}{2^k}
\le \sum_{k=1}^n \frac{1}{2^k}
\le \sum_{k=1}^\infty \frac{1}{2^k}
= 1.
\]
Hence $S_n(\omega) \le 1$ for all $n$ and all $\omega$.

**Step 3. Use monotone bounded convergence (pointwise).**  
For each fixed $\omega$, the sequence $S_n(\omega)$ is monotone nondecreasing and bounded above by $1$, so
\[
S_\infty(\omega) := \lim_{n\to\infty} S_n(\omega)
\]
exists in $[0,1]$.

### **Conclusion.**  
$S_n \to S_\infty$ pointwise, hence
\[
S_n \xrightarrow{a.s.} S_\infty.
\]

---

## **Key Takeaways**
- Monotone + bounded (pointwise) implies existence of a limit.  
- You do **not** need fancy theorems here, just real analysis on each sample path.  
- It is often helpful to compare to a geometric series when you see $2^{-k}$ weights.

---

# **(a)(ii) Limits of $E[S_n]$ and $\operatorname{Var}(S_n)$**

## **Assumptions / Notation**

- $S_n = \sum_{k=1}^n X_k / 2^k$.  
- $X_k \sim \text{Bernoulli}(1/2)$ iid, so:
  \[
  E[X_k] = \frac12, \quad \operatorname{Var}(X_k) = \frac14.
  \]
- From (a)(i): $S_n \uparrow S_\infty$ almost surely and $0 \le S_n \le 1$.

---

## **Solution – Expectation**

### **Claim.**  
\[
E[S_n] \xrightarrow[n\to\infty]{} E[S_\infty]
\quad\text{and}\quad
E[S_\infty] = \frac12.
\]

### **Proof.**

**Step 1. Compute $E[S_n]$.**  
By linearity of expectation:
\[
E[S_n]
= E\Big[\sum_{k=1}^n \frac{X_k}{2^k}\Big]
= \sum_{k=1}^n \frac{E[X_k]}{2^k}.
\]
Since $E[X_k]=1/2$,
\[
E[S_n]
= \frac12 \sum_{k=1}^n \frac{1}{2^k}.
\]

**Step 2. Evaluate the geometric sum.**  
For $r = 1/2$,
\[
\sum_{k=1}^\infty r^k = \frac{r}{1-r} = 1.
\]
Hence,
\[
\lim_{n\to\infty} E[S_n]
= \frac12 \cdot 1 = \frac12.
\]

**Step 3. Justify passing the limit inside the expectation.**  
From (a)(i), $0 \le S_n \uparrow S_\infty$, so by the **Monotone Convergence Theorem**,
\[
\lim_{n\to\infty} E[S_n] = E\Big[\lim_{n\to\infty} S_n\Big] = E[S_\infty].
\]

Thus $E[S_\infty] = 1/2$.

### **Conclusion.**  
\[
E[S_n] \to E[S_\infty]
\quad\text{and}\quad
E[S_\infty] = \frac12.
\]

---

## **Solution – Variance**

### **Claim.**  
\[
\operatorname{Var}(S_n) \xrightarrow[n\to\infty]{} \operatorname{Var}(S_\infty)
\quad\text{and}\quad
\operatorname{Var}(S_\infty) = \frac{1}{12}.
\]

### **Proof.**

**Step 1. Compute $\operatorname{Var}(S_n)$.**  
Since the $X_k$ are independent,
\[
\operatorname{Var}(S_n)
= \operatorname{Var}\Big(\sum_{k=1}^n \frac{X_k}{2^k}\Big)
= \sum_{k=1}^n \frac{\operatorname{Var}(X_k)}{4^k}
= \sum_{k=1}^n \frac{1/4}{4^k}
= \frac14 \sum_{k=1}^n \frac{1}{4^k}.
\]

**Step 2. Evaluate the geometric sum.**  
For $r = 1/4$,
\[
\sum_{k=1}^\infty r^k = \frac{r}{1-r} = \frac{1/4}{3/4} = \frac13.
\]
So,
\[
\lim_{n\to\infty} \operatorname{Var}(S_n)
= \frac14 \cdot \frac13 = \frac{1}{12}.
\]

**Step 3. Justify $\operatorname{Var}(S_n)\to\operatorname{Var}(S_\infty)$.**  
Recall:
\[
\operatorname{Var}(S_n) = E[S_n^2] - (E[S_n])^2.
\]

From (a)(i), $S_n \uparrow S_\infty$ and $0\le S_n\le 1$, so $S_n^2 \uparrow S_\infty^2$ and $0\le S_n^2\le 1$.  
By Monotone Convergence,
\[
E[S_n^2] \to E[S_\infty^2].
\]
We already know $E[S_n]\to E[S_\infty]$. Therefore:
\[
\operatorname{Var}(S_n)
= E[S_n^2] - (E[S_n])^2
\longrightarrow
E[S_\infty^2] - (E[S_\infty])^2
= \operatorname{Var}(S_\infty).
\]

Since the numerical limit is $1/12$, we conclude $\operatorname{Var}(S_\infty)=1/12$.

### **Conclusion.**  
\[
E[S_\infty] = \frac12,
\qquad
\operatorname{Var}(S_\infty) = \frac{1}{12}.
\]

---

## **Key Takeaways**
- MCT is your friend whenever you have $X_n \uparrow X$ and $X_n \ge 0$.  
- Always distinguish:
  - numerical limits like $\operatorname{Var}(S_n)\to c$  
  - vs interchange-of-limit-and-expectation statements like $\operatorname{Var}(S_\infty)=c$.  
- This construction is essentially a **random binary expansion** in $[0,1]$.

---

# **(b) Convergence of the Product $\prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}$**

## **Assumptions / Notation**

- $S_n = \sum_{k=1}^n X_k / 2^k$.  
- Characteristic function of $X_k\sim \text{Bernoulli}(1/2)$:
  \[
  \varphi_{X_k}(t) = E[e^{it X_k}] = \frac12(1+e^{it}).
  \]
- Independence of $(X_k)$.

---

## **Solution**

### **Claim.**  
For each fixed $t\in\mathbb{R}$,
\[
\prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}
\]
converges as $n\to\infty$.

### **Proof.**

**Step 1. Identify the product as a characteristic function.**  
For each $k$,
\[
E\Big[e^{i t X_k/2^k}\Big]
= \varphi_{X_k}\Big(\frac{t}{2^k}\Big)
= \frac{1 + e^{i t/2^k}}{2}.
\]

Since $S_n = \sum_{k=1}^n X_k/2^k$ and the $X_k$ are independent,
\[
\varphi_{S_n}(t)
= E[e^{it S_n}]
= E\Big[e^{it \sum_{k=1}^n X_k/2^k}\Big]
= \prod_{k=1}^n E\Big[e^{i t X_k/2^k}\Big]
= \prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}.
\]

So the product is exactly $\varphi_{S_n}(t)$.

**Step 2. Use convergence in distribution.**  
From (a)(i), $S_n \xrightarrow{a.s.} S_\infty$, hence $S_n \Rightarrow S_\infty$.

By Lévy’s continuity theorem (forward direction):  
If $S_n \Rightarrow S_\infty$, then
\[
\varphi_{S_n}(t) \to \varphi_{S_\infty}(t)
\quad \text{for each } t.
\]

Therefore the product
\[
\prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}
= \varphi_{S_n}(t)
\]
converges to $\varphi_{S_\infty}(t)$ as $n\to\infty$.

### **Conclusion.**  
For each $t\in\mathbb{R}$, the finite product converges:
\[
\prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2}
\longrightarrow \varphi_{S_\infty}(t).
\]

---

## **Key Takeaways**
- Recognizing a product as a characteristic function is a powerful trick.  
- Lévy’s continuity theorem connects convergence in distribution and convergence of characteristic functions:
  - $S_n \Rightarrow S_\infty \Rightarrow \varphi_{S_n} \to \varphi_{S_\infty}$.

---

# **(c) Distribution of $S_\infty$ via the Given Product Identity**

We are given:
\[
\prod_{k=1}^\infty \frac{1 + e^{i t/2^k}}{2} = \frac{e^{it} - 1}{it}, \quad t\in\mathbb{R}.
\]

## **Assumptions / Notation**

- From (b): for each $t$,
  \[
  \prod_{k=1}^n \frac{1 + e^{i t/2^k}}{2} = \varphi_{S_n}(t),
  \quad \varphi_{S_n}(t)\to \varphi_{S_\infty}(t).
  \]
- Identity to infinity:
  \[
  \prod_{k=1}^\infty \frac{1 + e^{i t/2^k}}{2}
  = \frac{e^{it} - 1}{it}.
  \]

---

## **Solution**

### **Claim.**  
$S_\infty \sim \text{Uniform}(0,1)$.

### **Proof.**

**Step 1. Compute the limiting characteristic function.**  
From (b),
\[
\varphi_{S_\infty}(t)
= \lim_{n\to\infty} \varphi_{S_n}(t)
= \prod_{k=1}^\infty \frac{1 + e^{i t/2^k}}{2}
= \frac{e^{it} - 1}{it}.
\]

**Step 2. Recognize the characteristic function.**  
The characteristic function of $\text{Uniform}(a,b)$ is
\[
\varphi_U(t)
= \frac{e^{itb} - e^{ita}}{it(b-a)}.
\]

For $a=0$, $b=1$,
\[
\varphi_{U(0,1)}(t)
= \frac{e^{it} - 1}{it}.
\]

So
\[
\varphi_{S_\infty}(t) = \varphi_{U(0,1)}(t) \quad \text{for all } t.
\]

**Step 3. Use uniqueness of characteristic functions.**  
If two distributions have the same characteristic function, then they are equal in distribution. Hence
\[
S_\infty \stackrel{d}{=} U(0,1).
\]

### **Conclusion.**  
\[
S_\infty \sim \text{Uniform}(0,1).
\]

---

## **Key Takeaways**
- Characteristic functions uniquely determine distributions.  
- The infinite Bernoulli binary expansion
  \[
  S_\infty = \sum_{k=1}^\infty \frac{X_k}{2^k}
  \]
  is a standard probabilistic construction of a $\text{Uniform}(0,1)$ random variable.  
- Lévy’s theorem (reverse direction): if $\varphi_n \to \varphi$ pointwise and $\varphi$ is a characteristic function, then the corresponding distributions converge weakly.

