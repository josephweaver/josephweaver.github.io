# 2024.Q1 – Variance Asymptotics, Normalized Convergence, and Almost Sure Limits
*:contentReference[oaicite:1]{index=1}*

## **Problem Statement (verbatim)**

Let $\{X_n, n \ge 1\}$ be a sequence of random variables such that  
$$
E(X_n)=0, \qquad  
E(X_n^2)=\frac{1}{n\ln(n+1)}, \qquad  
E(X_n X_{n+1})=\frac{2}{n^2},
$$
and  
$$
E(X_m X_n)=0 \quad \text{if } |m-n|\ge 2.
$$

---

### **(a)**  
Let $\sigma_n^2 = \mathrm{Var}(S_n)$ where $S_n=\sum_{i=1}^n X_i$.  
Prove that  
$$
\lim_{n\to\infty} \frac{\sigma_n^2}{\ln\ln n} = 1.
$$

---

### **(b)**  
Prove that for every sequence $\{a_n\}$ of positive numbers with $a_n\to\infty$,
$$
\frac{S_n}{\sqrt{a_n \ln\ln n}} \longrightarrow 0 
\quad \text{in probability and in } L^2.
$$

---

### **(c)**  
For every $\varepsilon>0$ prove:

(i)  
$$
\sum_{n=1}^\infty 
E\!\left[\frac{S_n^2}{\,n\ln n (\ln\ln n)^{2+\varepsilon}}\right] < \infty, 
\quad\text{and hence } 
\sum_{n=1}^\infty 
\frac{S_n^2}{\,n\ln n (\ln\ln n)^{2+\varepsilon}}
\text{ converges a.s.}
$$

(ii)  
$$
\lim_{n\to\infty} 
\frac{|S_n|}{\sqrt{n\ln n (\ln\ln n)^{2+\varepsilon}}} = 0
\quad \text{a.s.}
$$

---

# **Survival-Guide Writeup**

---

# **Part (a)**  
## **Claim.**  
$$
\lim_{n\to\infty} \frac{\sigma_n^2}{\ln\ln n} = 1.
$$

## **Proof.**

Start from the variance identity:
$$
\sigma_n^2 
= \mathrm{Var}(S_n)
= \sum_{i=1}^n E(X_i^2)
+ 2\sum_{1\le i<j\le n} E(X_i X_j).
$$

Given:
- $E(X_i^2)=\frac{1}{i\ln(i+1)}$,
- only adjacent pairs have nonzero covariance:  
  $E(X_i X_{i+1})=\frac{2}{i^2}$.

Thus
$$
\sigma_n^2
=\sum_{i=1}^n \frac{1}{i\ln(i+1)}
+\sum_{i=1}^{n-1} \frac{4}{i^2}.
$$

The second sum converges:
$$
\sum_{i=1}^\infty \frac{4}{i^2}=O(1).
$$

Hence the asymptotics are governed entirely by  
$$
\sum_{i=2}^n \frac{1}{i\ln(i+1)}.
$$

Use the expansion
$$
\frac{1}{i\ln(i+1)}
= \frac{1}{i\ln i}
- \frac{\ln(1+1/i)}{i\ln i \ln(i+1)}
= \frac{1}{i\ln i} + O\!\left(\frac1{i^2(\ln i)^2}\right).
$$

Thus
$$
\sum_{i=2}^n \frac{1}{i\ln(i+1)}
= \sum_{i=2}^n \frac{1}{i\ln i} + O(1).
$$

By the integral test:
$$
\sum_{i=2}^n \frac{1}{i\ln i}
= \ln\ln n + O(1).
$$

Putting everything together:
$$
\sigma_n^2 = \ln\ln n + O(1).
$$

Therefore
$$
\frac{\sigma_n^2}{\ln\ln n} \to 1.
$$

## **Conclusion.**  
The dominating contribution to $\sigma_n^2$ is the harmonic–logarithmic term  
$\sum 1/(i\ln i)$, and all other contributions are $O(1)$.  
Thus $\sigma_n^2 \sim \ln\ln n$.

## **Key Takeaways**
- Use decomposition:  
  $\mathrm{Var}(S_n)=\sum \mathrm{Var}(X_i)+2\sum\mathrm{Cov}(X_i,X_j)$.
- Identify when covariance structure is “local” (only neighbors matter).
- Integral test for $\sum 1/(i\ln i)$ leading to $\ln\ln n$.
- Asymptotic manipulations of slowly varying functions.

---

# **Part (b)**  
## **Claim.**  
If $a_n\to\infty$, then
$$
\frac{S_n}{\sqrt{a_n\ln\ln n}} \to 0 
\quad\text{in } L^2 \text{ and in probability}.
$$

## **Proof.**

Since $E(S_n)=0$,
$$
E\!\left[\left(\frac{S_n}{\sqrt{a_n\ln\ln n}}\right)^2\right]
=\frac{\sigma_n^2}{a_n\ln\ln n}.
$$

From part (a),  
$$
\sigma_n^2 \sim \ln\ln n.
$$

Therefore
$$
\frac{\sigma_n^2}{a_n\ln\ln n}
\sim \frac{1}{a_n}\to 0,
$$
because $a_n\to\infty$.

Thus
$$
\frac{S_n}{\sqrt{a_n\ln\ln n}} \to 0 \quad \text{in } L^2.
$$

Since $L^2\to 0$ implies convergence in probability,
the result follows.

## **Conclusion.**  
The scaling by $\sqrt{a_n\ln\ln n}$ dominates the growth of the variance of $S_n$, forcing the normalized sequence to converge to zero.

## **Key Takeaways**
- $L^2$-convergence can be checked by variance alone when means are zero.
- If variance goes to zero, convergence in probability follows immediately.
- The “natural size” of $S_n$ is $\sqrt{\ln\ln n}$, so any additional divergence in $a_n$ kills the ratio.

---

# **Part (c)(i)**  
## **Claim.**  
$$
\sum_{n=1}^\infty
E\!\left[\frac{S_n^2}{n\ln n (\ln\ln n)^{2+\varepsilon}}\right]
<\infty,
$$
and therefore  
$$
\sum_{n=1}^\infty
\frac{S_n^2}{n\ln n (\ln\ln n)^{2+\varepsilon}}
\quad \text{converges a.s.}
$$

## **Proof.**

Compute the expectation term:
$$
E\!\left[\frac{S_n^2}{n\ln n(\ln\ln n)^{2+\varepsilon}}\right]
= \frac{\sigma_n^2}{n\ln n (\ln\ln n)^{2+\varepsilon}}.
$$

Using $\sigma_n^2 \sim \ln\ln n$:
$$
\frac{\sigma_n^2}{n\ln n (\ln\ln n)^{2+\varepsilon}}
\sim
\frac{1}{n\ln n (\ln\ln n)^{1+\varepsilon}}.
$$

Test convergence via the integral test:
$$
\int^\infty \frac{dx}{x\ln x (\ln\ln x)^{1+\varepsilon}} < \infty
\quad (\varepsilon>0).
$$

Thus
$$
\sum_n E[Z_n] < \infty,
\quad Z_n := \frac{S_n^2}{n\ln n(\ln\ln n)^{2+\varepsilon}} \ge 0.
$$

By the Monotone Convergence Theorem,
finite expectation of a nonnegative series implies the series converges a.s.

## **Conclusion.**  
The normalization kills the growth of $S_n^2$ strongly enough to give absolute almost sure convergence.

## **Key Takeaways**
- If $\sum E(Z_n)<\infty$ and $Z_n\ge0$, then $\sum Z_n$ converges a.s.
- Integral test is a crucial tool for slowly varying functions.
- Useful trick: replace $\sigma_n^2$ with its asymptotic equivalent.

---

# **Part (c)(ii)**  
## **Claim.**  
$$
\lim_{n\to\infty}
\frac{|S_n|}{\sqrt{n\ln n (\ln\ln n)^{2+\varepsilon}}}=0 
\quad\text{a.s.}
$$

## **Proof.**

From part (c)(i), we know the series  
$$
\sum_{n=1}^\infty 
\frac{S_n^2}{n\ln n(\ln\ln n)^{2+\varepsilon}}
$$
converges a.s.

A necessary condition for convergence of the terms is:
$$
\frac{S_n^2}{n\ln n(\ln\ln n)^{2+\varepsilon}} \to 0 
\quad\text{a.s.}
$$

Taking square roots:
$$
\frac{|S_n|}{\sqrt{n\ln n(\ln\ln n)^{2+\varepsilon}}}\to 0 \quad\text{a.s.}
$$

## **Conclusion.**  
Almost sure convergence of a series implies its terms must tend to zero. Applying this to $S_n^2$ with the given normalization yields the desired a.s. convergence.

## **Key Takeaways**
- “Series converges a.s.” $\implies$ “its terms $\to 0$ a.s.”
- Classic method: reduce a strong a.s. statement to earlier summability results.
- Normalization $\sqrt{n\ln n(\ln\ln n)^{2+\varepsilon}}$ is much larger than the natural scale $\sqrt{\ln\ln n}$.

---

# **END OF SURVIVAL GUIDE ENTRY**
