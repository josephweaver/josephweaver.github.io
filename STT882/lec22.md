# 22 — Convergence of Conditional Expectations
STT 882  
March 12, 2025
**Topic:** Conditional Expectation, Increasing Filtrations, UI Martingales, Kolmogorov 0–1, DCT for Conditional Expectations

---

## 1. Review from Monday

### (1) Conditional expectations form a uniformly integrable family
Let $(\Omega, \mathcal{F}_0, P)$ with $E|X| < \infty$.  
Then
$$
\{ E_{\mathcal{F}}(X) : \mathcal{F} \subseteq \mathcal{F}_0 \}
$$
is **uniformly integrable (UI)**.

---

### (2) UI martingales converge in $L^1$
If $\{X_n, \mathcal{F}_n\}_{n\ge1}$ is a UI martingale, then
$$
X_n \xrightarrow{\text{a.s.}} X, \qquad 
X_n \xrightarrow{L^1} X
$$
and equivalently,
$$
E|X_n - X| \to 0.
$$

---

### (3) Conditional expectations along filtrations
Given $X_n = E_{\mathcal{F}_n}(X)$, $n\ge1$.

---

## 2. Convergence of Conditional Expectations Along an Increasing Filtration

### Theorem  
Let $(\Omega, \mathcal{F}_0, P)$ with $E|X| < \infty$.  
Suppose
$$
\mathcal{F}_1 \subseteq \mathcal{F}_2 \subseteq \dots \subseteq \mathcal{F}_0, 
\qquad \mathcal{F} = \sigma\left( \bigcup_{n\ge1} \mathcal{F}_n \right).
$$
Then
$$
E_{\mathcal{F}_n}(X) \xrightarrow[\text{a.s.}]{L^1} E_{\mathcal{F}}(X).
$$

### Proof Sketch
1. $X_n := E_{\mathcal{F}_n}(X)$ is a martingale and UI  
   (by the earlier results).
2. By UI martingale convergence:
   $$
   X_n \to X_\infty \quad \text{a.s. and in } L^1.
   $$
3. Need to show $X_\infty = E_{\mathcal{F}}(X)$.

   Check equality of integrals:
   $$
   E(X_n; A) = E(X; A), \qquad \forall A \in \mathcal{F}_n.
   $$
   Passing to limit:
   $$
   E(X_\infty; A) = E(X; A), \qquad \forall A \in \bigcup_n \mathcal{F}_n.
   $$

4. Use **Dynkin’s π–λ theorem** to extend from the algebra  
   generated by $\cup_n \mathcal{F}_n$ to all of $\mathcal{F}$.  
   Conclude:
   $$
   X_\infty = E_{\mathcal{F}}(X).
   $$

---

## 3. Application (a): Conditional probabilities stabilize

Let $\mathcal{F} = \sigma\{\mathcal{F}_n : n\ge1\}$.  
Then for any event $A\in\mathcal{F}$:
$$
P_{\mathcal{F}_n}(A) \xrightarrow[\text{a.s.}]{L^1} \mathbf{1}_A.
$$

Interpretation:  
As the filtration gains more information, the conditional probability  
of an event in the limit $\mathcal{F}$ collapses to either 0 or 1.

---

## 4. Application (b): New proof of **Kolmogorov’s 0–1 Law**

If $A$ is a **tail event**, then
$$
P(A) \in \{0,1\}.
$$

### Sketch
- Tail σ–field $\mathcal{T} = \bigcap_{n} \sigma(X_{n+1}, X_{n+2},\dots)$.
- For $A\in\mathcal{T}$, $P_{\mathcal{F}_n}(A)\to 1_A$ a.s.
- But $A$ is independent of $\mathcal{F}_n$, hence  
  $P_{\mathcal{F}_n}(A) = P(A)$.
- Thus $P(A) = 1_A$ almost surely; hence $P(A)=0$ or $1$.

---

## 5. Dominated Convergence for Conditional Expectations

Let $Y_n \to Y$ a.s., and $|Y_n|\le X$ with $E|X|<\infty$.  
Then
$$
E_{\mathcal{G}}(Y_n) \to E_{\mathcal{G}}(Y) \quad \text{a.s. and in } L^1.
$$

### Key steps (from the handwritten derivation)
- Apply bounded convergence to  
  $E\big( |Y_n - Y| \,\big|\,\mathcal{G} \big)$.
- Use that conditional expectation preserves inequalities.
- Extend to dominated case via absolute values and truncation.

---

## 6. Example (from last page)

Let $Y_n = Y \cdot \mathbf{1}_{\{|Y| \le n\}}$.  
Then $Y_n \to Y$ a.s. and $|Y_n|\le |Y|$.  
Thus
$$
E_{\mathcal{G}}(Y_n) \to E_{\mathcal{G}}(Y).
$$

Also shown:  
If $\sum_k P(|Y_k|>1)=\infty$, pathological behaviors can occur  
(example from the notes).

---

# Summary

Lecture 23 develops:

- Conditional expectations along increasing filtrations.
- Martingale convergence using uniform integrability.
- The limit being $E_{\mathcal{F}}(X)$, proved with Dynkin’s π–λ theorem.
- Applications:  
  - Conditional probabilities converge to indicator functions.  
  - Kolmogorov’s 0–1 law (new proof).  
- Dominated convergence theorem for conditional expectations.

