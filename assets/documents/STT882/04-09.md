Mankov Property.

$$
\begin{aligned}
& \Omega=C[0, \infty] \\
& \exists_{t}^{0}=\sigma\left\{B_{s}: 0 \leq s \leq t\right\} \\
& \left\{P_{x}\right\} x \in \mathbb{R} \quad P_{x}\left(B_{0}=x\right)=1 \\
& \quad P_{0}\left(B_{0}=0\right)=1 \Rightarrow \text { Dis of } S B M \\
& \quad P_{x}(A)=P_{0}(A-x)
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2025_11_25_b181001ce593e417e593g-1.jpg?height=255&width=429&top_left_y=259&top_left_x=721)
![](https://cdn.mathpix.com/cropped/2025_11_25_b181001ce593e417e593g-1.jpg?height=154&width=628&top_left_y=1267&top_left_x=210)
(A) Claim $E_{\mathcal{F}_{t}^{0}}^{x}(Y \circ \theta)_{t}=E^{B_{t}^{*}}(Y), \forall Y:([0,00] \rightarrow R$, bdd. veasureable,

Example
$Y=\int_{0}^{1} B_{s} \partial s$. this integal is Rewilone
$Y=\prod_{k=1}^{\delta} f_{k}\left(B_{h k}\right)$
$0<h_{1}<h_{2}<\ldots<h_{\partial}$
$f_{k}: \mathbb{R} \rightarrow \mathbb{R}$, bdd. $k=1, \ldots, d$.

$$
\begin{aligned}
& Y=\operatorname{Max}_{b \leq t \leq 7}\left\{B_{t}\right\} \\
& Y_{0} \theta_{t}=\sum_{k=1}^{\alpha} f_{k}\left(B_{t+h_{k}}\right) \\
& \theta_{t}(\omega)(s)=\omega(t+s), \quad 0 \leq s
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2025_11_25_b181001ce593e417e593g-2.jpg?height=324&width=572&top_left_y=517&top_left_x=210)

$$
2
$$

$E_{\mathcal{J}_{t}^{0}}$
â†‘ condition an up to tive $t$.

$$
\begin{aligned}
& g(y)=E^{y}(Y), y \in \mathbb{R} . \\
& g\left(B_{t}^{\alpha}\right)=E^{B_{t}^{\alpha}}(Y)
\end{aligned}
$$

Lever that's (B)
$\left[\begin{array}{l}\text { Lemma: }: x \in \mathcal{F}, \vec{y}=\left(\mu_{1}, \ldots, y_{\partial}\right), \vec{y} \| \mathcal{F} \\ \text { then: } E_{\mathcal{F}} f(x, \vec{y})=g(x) \quad g(x)=E[f(x, \vec{Y})] \quad x \in R .\end{array}\right]$
$f: \mathbb{R}^{\partial+1} \rightarrow \mathbb{R}$
Sargs $X 3, Y$ are ind.
Easy to Prove col Pobini.
WTS: $E(F(X, Y) \perp A)^{G}=E\left(g(x) \cdot l_{A} \times\right)^{G \in \tilde{\sigma}}, G$ is r.k. Bowd.
$A \in F \quad F$ ix $\times 3 G$ integrette over $Y$ tews.
$\chi, G \in \mathcal{F}$ calc thes First:
$y+\widetilde{f} \quad E(i f(x, \hat{y}), g] \quad x, y \in \mathbb{R}$.
(A) $\Rightarrow \quad E^{x}\left(Y_{0} \theta_{t}\right)=E^{x}\left[E^{B_{t}^{x}}(y)\right]$

By Expectation

$$
\begin{aligned}
& \text { raving } \\
& \left.F^{\tilde{x}}\left(V \circ A_{c}\right) \stackrel{\text { as }}{=} F^{\tilde{B_{t}}}(V) \quad H V \cdot\left(r_{m} m\right)\right) \rightarrow D \quad \text { L. } d_{r} \text { laorci.nd. }
\end{aligned}
$$

Resaring

$$
E_{f_{t}^{0}}^{\tilde{x}}\left(Y \circ \theta_{t}\right) \stackrel{\text { as }}{=} E^{\tilde{B}_{t}^{\tilde{x}}}(Y), \quad \forall Y:([0, \infty)) \rightarrow R \text {, bdd, necsure }
$$

MCT.
on friduy we mention monotone cluss theoren. w/ $x$-syster.
will take $Y=\sum_{k=1}^{d} f_{k}\left(B_{n_{k}}\right)$ to prove levanthel Cenera.

$$
\text { Nts: } \quad E_{\tilde{f}_{t}^{0}}^{\tilde{x}} \lambda_{k=1}^{\delta} f_{k}\left(B_{t}^{\tilde{x}}+h_{k}\right)=E^{\tilde{x}}\left[\lambda_{k=1}^{0} f_{k}\left(B_{n_{k}}\right)\right]
$$

Notation: Does this Denote. Another given? a Stutiny Point.
to Prove
using the lemma. $X=B_{t}^{\tilde{x}}, Y_{k}=B_{t+h_{k}}^{\tilde{x}}-B_{t}^{\tilde{x}} \quad k=1, \ldots, d$.

$$
\vec{Y}=\left(Y_{1}, \ldots, Y_{\partial}\right) \leq \mathcal{F}_{t}^{0}
$$

Each is increment, therefore by ind. incre. From Brownher Motions
therefore we cer use Each is incren

$$
\begin{gathered}
f(x, \vec{y})=\sum_{k=1}^{\delta} f_{k}\left(B_{t}^{\tilde{x}}+\left(B_{t+n k}^{\tilde{x}}-B_{t}^{\tilde{x}}\right)\right] \\
x+\hat{u}_{k}
\end{gathered}
$$

By (B)

$$
\begin{aligned}
g(x) & =E^{\tilde{x}} r_{k=1}^{d} f_{k}\left(x+B_{t+h_{k}}^{\tilde{x}}-B_{t}^{\tilde{y}}\right) \\
& =E_{h_{k}}^{\tilde{x}} r_{k=1}^{d} f_{k}\left(x+B_{h_{k}}\right) \\
& =E^{x}\left[\prod_{k=1}^{d} f_{k}\left(B_{h_{k}}\right)\right] \\
g\left(B_{t}^{\tilde{x}}\right) & =E^{B_{k}^{z}}\left[\prod_{k=1}^{0} f_{k}\left(B h_{k}\right)\right]
\end{aligned}
$$

the Ansem is $g\left(B_{t}^{*}\right)$.

* inituative given ind. inc. Then we will do it right

Ex:(1) $R=\inf \left\{t>1 ; B_{t}=0\right\}$.
![](https://cdn.mathpix.com/cropped/2025_11_25_b181001ce593e417e593g-3.jpg?height=269&width=759&top_left_y=2202&top_left_x=360)
$t_{0}=\operatorname{irf}\left\{t \geq 0 ; B_{t}=0\right\}$

$$
Y=\mathbb{1}_{\left\{T_{0}>1\right\}} \circ \theta_{1}=\mathbb{1}_{\{R>1+t\}} \text { shift By } 1 \text { eq Ignere Before } 1 .
$$

Probablity if we stant Brown'm not ow at $y$

$$
P_{t}(x, y)=f_{N(x, t)}(y)=\frac{1}{\sqrt{2 \pi t}} e^{-\frac{1}{2 t}(y-x)^{2}},-\infty<y<\infty
$$

Example.

$$
L=\sup \left\{t \leq 1: B_{t}=0\right\}
$$

then $P_{0}(L \leqslant t)=\int_{-\infty}^{\infty} P_{t}(0, y) P_{y}\left(T_{0}>1-t\right) \partial y . \quad t \leq 1$
![](https://cdn.mathpix.com/cropped/2025_11_25_b181001ce593e417e593g-4.jpg?height=323&width=553&top_left_y=1061&top_left_x=143)

$$
\mathbb{1}_{\left\{T_{0}>1-t\right\}^{0} \theta_{t}}=\mathbb{1}_{\{L \leqslant t\}}
$$

